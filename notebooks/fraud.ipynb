{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87eebf33",
   "metadata": {},
   "source": [
    "## Credit Card Transaction Demo\n",
    "\n",
    "In this notebook, we demonstate how the `moco` optimization library can be used to accelerate a pre-trained binary classifier trained to flag credit card transactions as fraudulent.\n",
    "\n",
    "It does this by reducing the average number of FLOPS (floating point operations) that the model needs to run inference on the entire dataset. Critically, `moco` finds subspaces of the input space where the prediction is a simple linear or constant function. At runtime, the derived model determines which subspace the transaction is a member of, and then executes the associated map with that subspace.\n",
    "\n",
    "This results in lower energy use, lower latency, higher throughput and less hardware needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a74ba7",
   "metadata": {},
   "source": [
    "| experiment   |   Latency per transaction, raced (s) |   Number of FLOPs per transaction (ms) |   Precision |   Recall |\n",
    "|:-------------|--------------------------------------:|---------------------------------------:|------------:|---------:|\n",
    "| baseline     |                           4.80942e-05 |                                 3104   |    0.785714 | 0.916667 |\n",
    "| optimized    |                           2.18402e-05 |                                 1627.6 |    0.785714 | 0.916667 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f1db5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Callable\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57c431",
   "metadata": {},
   "source": [
    "### Step 1: Audio initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df[[col for col in df.columns if col.startswith('V')]].to_numpy()\n",
    "    y = df['Class'].to_numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0118e",
   "metadata": {},
   "source": [
    "Load the dataset. The dataset is heavily imbalanced -- it consists of mostly non-fraudulent transactions (only 0.17% of the 280k+ transactions are fraudulent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "X, y = load_dataset('/Users/samrandall/Downloads/creditcard.csv')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 2)\n",
    "\n",
    "X.shape, pd.Series(y).value_counts().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train initial model\n",
    "mlp = MLPClassifier(random_state = 4)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    mlp, X_val, y_val, name=\"MLP\", plot_chance_level=True, despine=True\n",
    ")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9388c56f",
   "metadata": {},
   "source": [
    "## Choose a threshold based on precision-recall curve on validation set.\n",
    "- I chose `threshold = {}`, achieving `precision = {}` and `recall = {}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "y_hat_t_train = mlp.predict_proba(X_train)[:, 1] > threshold\n",
    "y_hat_t_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e62048",
   "metadata": {},
   "source": [
    "## Benchmark its latency and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba36b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_t_test = mlp.predict_proba(X_test)[:, 1] > threshold\n",
    "p, r, _, _ = precision_recall_fscore_support(y_hat_t_test, y_test, average = 'binary')\n",
    "p, r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056c187",
   "metadata": {},
   "source": [
    "The precision we get is 70% and the recall we get is 100% on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    def predict(self, x):\n",
    "        h = np.max(x @ self.w[0] + self.b[0], 0)\n",
    "        for W, b in zip(self.w[1:-1], self.b[1:-1]):\n",
    "            h = np.max(h @ W + b, 0)\n",
    "        out = h @ self.w[-1] + self.b[-1]\n",
    "        prob = 1 / (1 + np.exp(-out))\n",
    "        return prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63382bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_mlp(x, weights, biases):\n",
    "    h = np.max(x @ weights[0] + biases[0], 0)\n",
    "    for W, b in zip(weights[1:-1], biases[1:-1]):\n",
    "        h = np.max(h @ W + b, 0)\n",
    "    out = h @ weights[-1] + biases[-1]\n",
    "    prob = 1 / (1 + np.exp(-out))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_timings = []\n",
    "# Warmup\n",
    "for i in range(100):\n",
    "    s = time.perf_counter()\n",
    "    mlp.predict_proba(X_test[i: i + 1])[:, 1] > threshold\n",
    "    e = time.perf_counter()\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    x = X_test[i: i + 1]\n",
    "    s = time.perf_counter()\n",
    "    \n",
    "    for j in range(3):\n",
    "        forward_mlp(x, mlp.coefs_, mlp.intercepts_)\n",
    "    e = time.perf_counter()\n",
    "    original_timings.append((e - s) / 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f65b4d",
   "metadata": {},
   "source": [
    "On average, it takes 6.41E-6 seconds or 6 microseconds (us) to execute a transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afd9f5",
   "metadata": {},
   "source": [
    "## FLOPs (Baseline)\n",
    "Next we baseline the FLOPS. The model is a two-layer MLP with a ReLU activation and than a sigmoid activation. \n",
    "Roughly, the number of FLOPS for the first layer to process one data point is (28 + 1) * 100.\n",
    "The number of FLOPS to process the second layer is (100 + 1) * 1. Note that in both cases we account for the bias term. \n",
    "The number of FLOPs associated with the ReLU is 100 and the the number of flops associated with the sigmoid is 3. \n",
    "In sum total, there are (28 + 1) * 100 + 100 + (100 * 1) + 1 + 3 = **3104 FLOPS**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fcdbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (W, b) in enumerate(zip(mlp.coefs_, mlp.intercepts_)):\n",
    "    print(f\"Layer {i}: {W.shape} {b.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008564b",
   "metadata": {},
   "source": [
    "## Accelerating the model with `moco`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moco.partition import Partition, RoutedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train = mlp.predict_proba(X_train)[:, 1] > threshold\n",
    "partition = Partition()\n",
    "C = 2\n",
    "partition.find_sufficient_groups(X_train, p_train, min_group_size = X_train.shape[0] / (C * 10))\n",
    "partition.summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b69cf",
   "metadata": {},
   "source": [
    "From the above summary table, we see that what we'll now do is create a Gated Model based on only the first group (`is_active == True` for that one, and not the second group). We see that the system generated a group of 182011 transactions, that were all not fraudulent. We fit a model to that, and that model identified 89757. We'll use that model in our new routed model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymlp = MyMLP(mlp.coefs_, mlp.intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb34707",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = RoutedModel.from_partition(partition, mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aadecf",
   "metadata": {},
   "source": [
    "## Evaluation of the `RoutedModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a145e4a",
   "metadata": {},
   "source": [
    "On the test set, we do not see a drop in precision or recall. The precision is `83.3%` in both and the recall is `87.5%` in both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f970e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_train_new = rm.predict(X_train)\n",
    "mlp_train_new = mlp.predict(X_train)\n",
    "print(\"train\")\n",
    "p, r, _, _ = precision_recall_fscore_support(mlp_train_new, y_train, average = 'binary')\n",
    "print(\"MLP\", p, r)\n",
    "p, r, _, _ = precision_recall_fscore_support(p_train_new, y_train, average = 'binary')\n",
    "print(\"Routed Model\", p, r)\n",
    "\n",
    "p_test_new = rm.predict(X_test)\n",
    "mlp_test = mlp.predict(X_test)\n",
    "\n",
    "print(\"test\")\n",
    "p, r, _, _ = precision_recall_fscore_support(mlp_test, y_test, average = 'binary')\n",
    "print(\"MLP\", p, r)\n",
    "\n",
    "mlp_precision = p\n",
    "mlp_recall = r\n",
    "p, r, _, _ = precision_recall_fscore_support(p_test_new, y_test, average = 'binary')\n",
    "print(\"Routed Model\", p, r)\n",
    "\n",
    "routed_precision = p\n",
    "routed_recall = r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151245d1",
   "metadata": {},
   "source": [
    "In terms of FLOPs, we can do a theoretical analysis, and then we will get to the latency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5cd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(partition.transform(X_test)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd596e",
   "metadata": {},
   "source": [
    "## FLOPs in the New Model\n",
    "Computed before for the original path is 3104 FLOPS / transaction. \n",
    "That occurs in the test set whenever we get nan's (51.5%) of the time. \n",
    "In both cases, whether the early exit path is used or not, we must evaluate it. \n",
    "`total_flops = (1 * Flops(early_exit)) + (g / N) * Flops(full model)`\n",
    "The FLOPs of the early exit (LogisticClassifier) are `28 * 1 + 1 = 29`. \n",
    "`(1 * 29) + (0.515) * 3104 = 1627.6` FLOPS\n",
    "This is a **48% reduction** in FLOPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ddcf16",
   "metadata": {},
   "source": [
    "## Real Time Latency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = RoutedModel.from_partition(partition, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def profile(prediction_method: Callable,\n",
    "    X: np.ndarray,\n",
    "    n_trials = 100,\n",
    "    n_samples = 1000\n",
    "):\n",
    "\n",
    "    times = np.zeros(n_samples)\n",
    "    b = 1\n",
    "    eyes = np.random.choice(len(X), n_samples, replace = False)\n",
    "    for j in range(10):\n",
    "        for i in eyes:\n",
    "            s = time.perf_counter()\n",
    "            prediction_method(X[i: i + b])\n",
    "            e = time.perf_counter()\n",
    "\n",
    "\n",
    "    for j in range(n_trials):\n",
    "        for i, idx in enumerate(eyes):\n",
    "            x = X[idx: idx + b]\n",
    "            s = time.perf_counter()\n",
    "            prediction_method(x)\n",
    "            e = time.perf_counter()\n",
    "            times[i] += e - s\n",
    "\n",
    "\n",
    "    return times / n_trials\n",
    "\n",
    "original_times = profile(mlp.predict, X_test)\n",
    "rm_times_raced = profile(rm.predict_race, X_test)\n",
    "rm_seq_times = profile(rm.predict, X_test)\n",
    "df = pd.DataFrame({\"original\": original_times, \"optimized_best_of\": rm_times_raced, \"optimized_sequential\": rm_seq_times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis = 0).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0223772",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup = df.mean(axis = 0).to_dict()\n",
    "ratio = speedup['optimized_best_of'] / speedup['original']\n",
    "ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e58687",
   "metadata": {},
   "source": [
    "## Latency Result\n",
    "We are now seeing an average of 2.82E-5 seconds per transaction, which is faster than 4.92E-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_analysis = {\n",
    "    \"experiment\": [\"baseline\", \"optimized\"],\n",
    "    \"Latency per transaction, raced (ms)\": [speedup['original'], speedup['optimized_best_of']],\n",
    "    \"Number of FLOPs per transaction (ms)\": [3104, 1627.6],\n",
    "    \"Precision\": [mlp_precision, routed_precision],\n",
    "    \"Recall\" : [mlp_recall, routed_recall]\n",
    "}\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark_analysis)\n",
    "s = benchmark_df.to_markdown()\n",
    "\n",
    "# Put this above as summary!\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c205d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moco-api-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
